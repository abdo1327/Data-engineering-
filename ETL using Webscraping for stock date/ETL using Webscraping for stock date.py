# -*- coding: utf-8 -*-
"""Final Assignment-bak-2024-02-07-06-11-25Z.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s-F0ELAuxXS6XEJhspEQCvVfcp2YJ5nf

<h1>Extracting and Visualizing Stock Data</h1>

This project showing how to  Extract essential data from a dataset and display it is a necessary part of data science; therefore individuals can make correct decisions based on the data. In this assignment, you will extract some stock data, you will then display this data in a graph.

#### 1.Define a Function that Makes a Graph
#### 2.Use `yfinance` to Extract Stock Data
#### 3.Use Webscraping (`BeautifulSoup`) to Extract Tesla Revenue Data
####  4.Use `yfinance` to Extract Stock Data
#### 5.Use Webscraping to Extract GME Revenue Data
#### 6.Plot Tesla Stock Graph
#### 7.Plot GameStop Stock Graph
"""

!pip install yfinance==0.1.67
!mamba install bs4==4.10.0 -y
!pip install nbformat==4.2.0

import yfinance as yf
import pandas as pd
import requests
from bs4 import BeautifulSoup
import plotly.graph_objects as go
from plotly.subplots import make_subplots

import warnings
# Ignore all warnings
warnings.filterwarnings("ignore", category=FutureWarning)

"""## Define Graphing Function

# Function Definition: make_graph
This section introduces the function `make_graph`, which takes two dataframes as inputs: one containing stock data with Date and Close columns, and another containing revenue data with Date and Revenue columns. Additionally, it requires the name of the stock.
"""

def make_graph(stock_data, revenue_data, stock):
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=("Historical Share Price", "Historical Revenue"), vertical_spacing = .3)
    stock_data_specific = stock_data[stock_data.Date <= '2021--06-14']
    revenue_data_specific = revenue_data[revenue_data.Date <= '2021-04-30']
    fig.add_trace(go.Scatter(x=pd.to_datetime(stock_data_specific.Date, infer_datetime_format=True), y=stock_data_specific.Close.astype("float"), name="Share Price"), row=1, col=1)
    fig.add_trace(go.Scatter(x=pd.to_datetime(revenue_data_specific.Date, infer_datetime_format=True), y=revenue_data_specific.Revenue.astype("float"), name="Revenue"), row=2, col=1)
    fig.update_xaxes(title_text="Date", row=1, col=1)
    fig.update_xaxes(title_text="Date", row=2, col=1)
    fig.update_yaxes(title_text="Price ($US)", row=1, col=1)
    fig.update_yaxes(title_text="Revenue ($US Millions)", row=2, col=1)
    fig.update_layout(showlegend=False,
    height=900,
    title=stock,
    xaxis_rangeslider_visible=True)
    fig.show()

"""## Use yfinance to Extract Stock Data

Using the `Ticker` function enter the ticker symbol of the stock we want to extract data on to create a ticker object. The stock is Tesla and its ticker symbol is `TSLA`.
"""

tasla = yf.Ticker("TSLA")

"""Using the ticker object and the function `history` extract stock information and save it in a dataframe named `tesla_data`. Set the `period` parameter to `max` so we get information for the maximum amount of time.

"""

tesla_data = tasla.history(period="max")

tesla_data.reset_index(inplace=True)
print(tesla_data.head())

"""## Webscraping Tesla Revenue Data

"""

html_data  = requests.get("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/revenue.htm").text

"""Parse the html data using `beautiful_soup`.

"""

soup = BeautifulSoup(html_data,"html.parser")

"""Using `BeautifulSoup` or the `read_html` function extract the table with `Tesla Revenue` and store it into a dataframe named `tesla_revenue`. The dataframe should have columns `Date` and `Revenue`.

"""

table = soup.find_all("tbody")[1]
Dates = []
tesla_revenues = []
for row in table.find_all('tr'):
    cols = row.find_all('td')
    Date = cols[0].get_text(strip=True)
    tesla_revenue = cols[1].get_text(strip=True)
    Dates.append(Date)
    tesla_revenues.append(tesla_revenue)

# Create a DataFrame from the lists
tesla_revenue = pd.DataFrame({'Date': Dates, 'Revenue': tesla_revenues})

"""Execute the following line to remove the comma and dollar sign from the `Revenue` column.

"""

tesla_revenue["Revenue"] = tesla_revenue['Revenue'].str.replace(',|\$',"")

tesla_revenue.dropna(inplace=True)

tesla_revenue = tesla_revenue[tesla_revenue['Revenue'] != ""]

print(tesla_revenue.tail())

"""## Use yfinance to Extract Stock Data for GME

"""

GameStop = yf.Ticker("GME")

gme_data = GameStop.history(period="max")

gme_data.reset_index(inplace=True)
print(gme_data.head())

"""## Webscraping GME Revenue Data

"""

html_data2  = requests.get("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/stock.html").text

soup2 = BeautifulSoup(html_data2,"html.parser")

"""Extract the table with GameStop Revenue and store it into a dataframe named gme_revenue."""

table2 = soup2.find_all("tbody")[1]
Dates2 = []
gme_revenues = []
for row in table2.find_all('tr'):
    cols = row.find_all('td')
    Date = cols[0].get_text(strip=True)
    gme_revenue = cols[1].get_text(strip=True)
    Dates2.append(Date)
    gme_revenues.append(gme_revenue)

# Create a DataFrame from the lists
gme_revenue = pd.DataFrame({'Date': Dates2, 'Revenue': gme_revenues})
gme_revenue["Revenue"] = gme_revenue['Revenue'].str.replace(',|\$',"")

print(gme_revenue.tail())

"""## Plot Tesla Stock Graph

Use the `make_graph` function to graph the Tesla Stock Data, also provide a title for the graph. The structure to call the `make_graph` function is `make_graph(tesla_data, tesla_revenue, 'Tesla')`. Note the graph will only show data upto June 2021.
"""

make_graph(tesla_data, tesla_revenue, 'Tesla')

"""## Plot GameStop Stock Graph

Use the `make_graph` function to graph the GameStop Stock Data, also provide a title for the graph. The structure to call the `make_graph` function is `make_graph(gme_data, gme_revenue, 'GameStop')`. Note the graph will only show data upto June 2021.
"""

make_graph(gme_data, gme_revenue, 'GameStop')

"""This work utilizes the contributions of Azim Hirjani ,this work part of the final project for obtaining IBM Data Analytics certification.

"""

