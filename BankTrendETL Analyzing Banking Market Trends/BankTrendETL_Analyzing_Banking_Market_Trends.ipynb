{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing the required libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "5XSAv4jxCgOe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `log_progress` function appends a message with a timestamp to a file named \"code_log.txt\", aiding in tracking progress or events during code execution.\n"
      ],
      "metadata": {
        "id": "rjpTFoxPC1Xv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lRQU7zZACbMP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def log_progress(message):\n",
        "\n",
        "    timestamp_format = '%Y-%h-%d-%H:%M:%S'  # Year-Monthname-Day-Hour-Minute-Second\n",
        "    now = datetime.now()  # get current timestamp\n",
        "    timestamp = now.strftime(timestamp_format)\n",
        "    with open(\"./code_log.txt\", \"a\") as f:\n",
        "        f.write(timestamp + ' : ' + message + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `extract` function fetches data from URL, parsing it using BeautifulSoup. It also extracts information from HTML tables with some  attributes and convert it to  df. each row should has three columns, Finally, it returns the DataFrame containing the extracted data.\n"
      ],
      "metadata": {
        "id": "c8ROq7LFDOi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(url, table_attribs):\n",
        "    page = requests.get(url).text\n",
        "    data = BeautifulSoup(page, 'html.parser')\n",
        "    df = pd.DataFrame(columns=table_attribs)\n",
        "    tables = data.find_all('tbody')\n",
        "    rows = tables[0].find_all('tr')\n",
        "    for row in rows:\n",
        "        col = row.find_all('td')\n",
        "\n",
        "        if len(col) == 3:  # Assuming each row has 3 columns\n",
        "            # Extract text from the second and third columns\n",
        "            name = col[1].text.strip()  # Get the text content, removing leading/trailing whitespaces\n",
        "            mc_usd_billion = float(col[2].text.strip())\n",
        "\n",
        "            # Create a dictionary with the extracted data\n",
        "            data_dict = {\"Name\": name, \"MC_USD_Billion\": mc_usd_billion}\n",
        "\n",
        "            # Create a DataFrame from the dictionary\n",
        "            df1 = pd.DataFrame(data_dict, index=[0])\n",
        "\n",
        "            # Concatenate the DataFrame to the main DataFrame\n",
        "            df = pd.concat([df, df1], ignore_index=True)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "_oGa5JP1DItg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `transform` function enhances the df by adding three  new columns, each containing the transformed market  values to the country  currency. It reads exchange rate data from a CSV file, converts it into a dictionary, and uses it to perform the currency conversions. The output is a df includes the 3 new  columns for markt values in GBP, EUR, and INR, rounded to two decimal.\n"
      ],
      "metadata": {
        "id": "Ffvf42c4D7Ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(df, csv_path):\n",
        "\n",
        "    exchange_rate_df = pd.read_csv(csv_path)\n",
        "    exchange_rate = exchange_rate_df.set_index('Currency')['Rate'].to_dict()\n",
        "\n",
        "    df['MC_GBP_Billion'] = np.round(df['MC_USD_Billion'] * exchange_rate['GBP'], 2)\n",
        "    df['MC_EUR_Billion'] = np.round(df['MC_USD_Billion'] * exchange_rate['EUR'], 2)\n",
        "    df['MC_INR_Billion'] = np.round(df['MC_USD_Billion'] * exchange_rate['INR'], 2)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Y9TdQVTpDzgc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following three functions will:\n",
        "1. Save the DataFrame to a CSV file.\n",
        "2. Save the DataFrame to a database table using the provided table name and connection.\n",
        "3. Execute a query on the specified database table and print the output.\n"
      ],
      "metadata": {
        "id": "hHkr7up7Eaos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_csv(df, output_path):\n",
        "    df.to_csv(csv_path)\n",
        "\n",
        "\n",
        "def load_to_db(df, sql_connection, table_name):\n",
        "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
        "\n",
        "\n",
        "def run_query(query_statement, sql_connection):\n",
        "\n",
        "    print(query_statement)\n",
        "    query_output = pd.read_sql(query_statement, sql_connection)\n",
        "    print(query_output)"
      ],
      "metadata": {
        "id": "2RS5QaLbEnod"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Run the code and to get the ETL pipline output"
      ],
      "metadata": {
        "id": "8TXwxyvAF1Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the webpage containing data about the largest banks\n",
        "url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
        "\n",
        "# Attributes of the table we want to extract from the webpage\n",
        "table_attribs = [\"Name\", \"MC_USD_Billion\"]\n",
        "\n",
        "# Path to the CSV file containing exchange rate information\n",
        "csv_path0 = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv'\n",
        "\n",
        "# Path to save the extracted data as a CSV file\n",
        "csv_path = './Largest_banks_data.csv'\n",
        "\n",
        "# Name of the database to save the data\n",
        "db_name = 'Banks.db'\n",
        "\n",
        "# Name of the table in the database to save the data\n",
        "table_name = 'Largest_banks'\n",
        "\n",
        "# Logging progress\n",
        "log_progress('Preliminaries complete. Initiating ETL process')\n",
        "\n",
        "# Extract data from the specified URL and table attributes\n",
        "df = extract(url, table_attribs)\n",
        "\n",
        "# Logging progress\n",
        "log_progress('Data extraction complete. Initiating Transformation process')\n",
        "\n",
        "# Transform the extracted data using exchange rate information\n",
        "df = transform(df, csv_path0)\n",
        "\n",
        "# Logging progress\n",
        "log_progress('Data transformation complete. Initiating loading process')\n",
        "\n",
        "# Save the transformed data to a CSV file\n",
        "load_to_csv(df, csv_path)\n",
        "\n",
        "# Logging progress\n",
        "log_progress('Data saved to CSV file')\n",
        "\n",
        "# Establish a connection to the SQLite database\n",
        "sql_connection = sqlite3.connect('Banks.db')\n",
        "\n",
        "# Logging progress\n",
        "log_progress('SQL Connection initiated.')\n",
        "\n",
        "# Load the transformed data into the database as a table\n",
        "load_to_db(df, sql_connection, table_name)\n",
        "log_progress('Data loaded to Database as table. Running the query')\n",
        "\n",
        "# Run queries on the database table and print the output\n",
        "query_statement = f\"SELECT * from {table_name} \"\n",
        "run_query(query_statement, sql_connection)\n",
        "\n",
        "query_statement = f\"SELECT AVG(MC_GBP_Billion) FROM  {table_name} \"\n",
        "run_query(query_statement, sql_connection)\n",
        "\n",
        "query_statement = f\"SELECT Name FROM  {table_name} LIMIT 5\"\n",
        "run_query(query_statement, sql_connection)\n",
        "\n",
        "# Logging progress\n",
        "log_progress('Process Complete.')\n",
        "\n",
        "# Close the SQL connection\n",
        "sql_connection.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqW9jZx4DIfh",
        "outputId": "2109e4ff-457e-4496-9d00-5cc28bad3bc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT * from Largest_banks \n",
            "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
            "0                           JPMorgan Chase          432.92          346.34   \n",
            "1                          Bank of America          231.52          185.22   \n",
            "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
            "3               Agricultural Bank of China          160.68          128.54   \n",
            "4                                HDFC Bank          157.91          126.33   \n",
            "5                              Wells Fargo          155.87          124.70   \n",
            "6                        HSBC Holdings PLC          148.90          119.12   \n",
            "7                           Morgan Stanley          140.83          112.66   \n",
            "8                  China Construction Bank          139.82          111.86   \n",
            "9                            Bank of China          136.81          109.45   \n",
            "\n",
            "   MC_EUR_Billion  MC_INR_Billion  \n",
            "0          402.62        35910.71  \n",
            "1          215.31        19204.58  \n",
            "2          180.94        16138.75  \n",
            "3          149.43        13328.41  \n",
            "4          146.86        13098.63  \n",
            "5          144.96        12929.42  \n",
            "6          138.48        12351.26  \n",
            "7          130.97        11681.85  \n",
            "8          130.03        11598.07  \n",
            "9          127.23        11348.39  \n",
            "SELECT AVG(MC_GBP_Billion) FROM  Largest_banks \n",
            "   AVG(MC_GBP_Billion)\n",
            "0              151.987\n",
            "SELECT Name FROM  Largest_banks LIMIT 5\n",
            "                                      Name\n",
            "0                           JPMorgan Chase\n",
            "1                          Bank of America\n",
            "2  Industrial and Commercial Bank of China\n",
            "3               Agricultural Bank of China\n",
            "4                                HDFC Bank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VIqgqiWQGLN8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pO2Cqlq8FPrZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}